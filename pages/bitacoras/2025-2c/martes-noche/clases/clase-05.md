---
layout: page
title: Clase 5
description: Martes Noche, 2025, Segundo Cuatrimestre
permalink: /bitacoras/2025-2c/martes-noche/clases/clase-05/
---

# Clase N¬∞5: Testing
*Desarrollo de Software K3552 (Martes Noche)*

**Fecha: 16 de Septiembre de 2025**

# Resumen

En esta clase introducimos los fundamentos del **testing** en desarrollo de software: conceptos clave, tipos de pruebas y su organizaci√≥n.

Tambi√©n veremos enfoques modernos como **BDD**, **mocking** y **TDD**, que ayudan a dise√±ar sistemas m√°s confiables y f√°ciles de mantener.

## üìë√çndice

- [Introducci√≥n](#introduccion)
- [Estructura](#estructura)
- [Automatizaci√≥n](#automatizacion)
- [Independencia](#independencia)
- [Clasificaci√≥n](#clasificacion)
	- [Unitarios](#unitarios)
	- [Integraci√≥n](#integracion)
	- [Funcionales (o E2E)](#funcionales)
	- [Pir√°mide de testing](#piramide-testing)
- [BDD](#bdd)
- [Mocking](#mocking)
- üî¥üü¢[TDD](#tdd)

<a id="introduccion"></a>
## Introducci√≥n

Cuando hablamos de **testing** nos referimos a la disciplina que permite verificar si el software cumple con lo esperado.

Aunque pueda sonar t√©cnico, la idea es bastante cotidiana. Pensemos en la compra de un auto: antes de salir a la ruta, uno prueba que arranque, que los frenos funcionen y que las luces respondan.

En el desarrollo de software ocurre lo mismo. Antes de confiar en un programa necesitamos comprobar que responde como se espera.

En la pr√°ctica, ning√∫n sistema est√° libre de errores. Sin embargo, podemos reducir la incertidumbre someti√©ndolo a distintas pruebas. Estas pruebas contrastan el resultado esperado con el real, y cuando aparecen diferencias, hablamos de *bugs*.  

> **Observaci√≥n**: Un conjunto de tests que nunca detecta errores seguramente no est√© cubriendo los escenarios correctos.

Para organizarlos, conviene pensar en los distintos caminos de ejecuci√≥n que un sistema puede recorrer:

- **Camino feliz:** todo sale seg√∫n lo previsto.

   > **Ejemplo:** un usuario ingresa sus credenciales correctas y accede al sistema.

- **Camino no feliz:** se presentan casos de error previsibles.

   > **Ejemplo:** un usuario escribe mal su contrase√±a y se le niega el acceso.

- **Caminos poco esperables:** situaciones extremas o poco comunes.

   > **Ejemplo:** intentar subir una foto de 10 GB a una red social.

La base para definir qu√© caminos conviene probar son los **requerimientos**. Cada requisito deber√≠a derivar en al menos un caso de prueba.

Para darles m√°s orden distinguimos dos niveles:

- **Clases de test:** agrupan conceptualmente las pruebas sobre una misma funcionalidad. Ejemplo: todos los tests de login.

- **Casos de test:** son instancias concretas con entradas, acciones y expectativas. Ejemplo: ‚Äúlogin con contrase√±a correcta concede acceso‚Äù.

<a id="estructura"></a>
## Estructura
Un test bien dise√±ado sigue una narrativa clara que puede resumirse en tres pasos:

1. **Precondiciones**: definimos el contexto inicial, configurando datos, objetos o estados necesarios.  
2. **Operaci√≥n**: realizamos la acci√≥n que queremos validar.  
3. **Postcondiciones**: verificamos el resultado esperado mediante aserciones.  

> **Observaci√≥n**: si la operaci√≥n no modifica el estado (por ejemplo, una funci√≥n pura), basta con validar el valor retornado.

M√°s adelante veremos un esquema que servir√° de gu√≠a en la mayor√≠a de los enfoques modernos de testing.

<a id="automatizacion"></a>
## Automatizaci√≥n

Automatizar tests no es un fin en s√≠ mismo: conviene hacerlo solo cuando aporta verdadero valor. Una forma de evaluarlo es hacerse estas tres preguntas:  

1. **¬øEs posible automatizar este test?**  
   
	S√≠, siempre que las entradas y salidas est√©n bien definidas.  

   > **Ejemplo:** un test unitario que valida la l√≥gica de una clase.  

2. **¬øQu√© beneficio aporta automatizarlo?**  
   
	La automatizaci√≥n brilla cuando necesitamos feedback r√°pido y confiable.  

   > **Ejemplo:** al construir un service que utiliza clases de dominio, podemos automatizar los tests para asegurarnos de que la l√≥gica central siga funcionando sin romperse.

3. **¬øSer√° mantenible en el tiempo?**  
   
	Un test que se rompe con cada cambio deja de ser una ayuda y se vuelve una carga.  

   > **Ejemplo:** un test de UI que falla cada vez que cambia el nombre de un bot√≥n termina dando m√°s ruido que certezas.  

En resumen, automatizar vale la pena en lo que es estable, r√°pido de ejecutar y √∫til a largo plazo. El resto conviene revisarlo manualmente.

<a id="independencia"></a>
## Independencia

Un principio b√°sico del testing es la **independencia**: cada test debe poder ejecutarse por s√≠ solo y ser determin√≠stico sin importar el contexto o el orden en que se ejecute.  

En la pr√°ctica, esto significa que:  

- No se deben **encadenar pruebas**, es decir, un test no debe preparar datos que otro necesite.  

   > **Ejemplo:** un test que crea un usuario no deber√≠a dejarlo disponible para que otro test lo use.  

- Se debe **restaurar el estado**: al terminar un test, todo deber√≠a volver a condiciones limpias.  

   > **Ejemplo:** si en un test agregamos elementos a una lista y no la vaciamos, otro test podr√≠a empezar con datos ‚Äúsucios‚Äù y fallar por un motivo ajeno a lo que realmente prueba.  

- Los tests deben poder **ejecutarse en paralelo** sin chocar entre s√≠.  

   > **Ejemplo:** dos tests que escriben en el mismo archivo al mismo tiempo pueden interferirse y dar errores falsos.  

Cuando se cumple este principio, los tests ofrecen resultados confiables y f√°ciles de interpretar.

<a id="clasificacion"></a>
## Clasificaci√≥n

<a id="unitarios"></a>
### Unitarios

Los **tests unitarios** se concentran en la **unidad m√≠nima de l√≥gica**, como una funci√≥n o un m√©todo.  

Su prop√≥sito es verificar que cada pieza del sistema hace exactamente lo que deber√≠a en aislamiento, sin depender de otros m√≥dulos.  

Tienen como ventaja que son r√°pidos de ejecutar, f√°ciles de escribir y localizan el error justo en el lugar donde ocurre.

> **Cuando una funci√≥n deja de comportarse como se espera, un test unitario deber√≠a detectarlo de inmediato.**  

Por ejemplo, con [Jest](https://jestjs.io/) podemos validar una funci√≥n simple:

```js
// suma.test.js
test('suma dos n√∫meros', () => {
  expect(sumar(2,3)).toBe(5);
});
```

<a id="integracion"></a>
### Integraci√≥n

Los **tests de integraci√≥n** verifican que varios m√≥dulos funcionen bien en conjunto.

Su prop√≥sito es detectar errores que no aparecen en unitarios, como datos mal formateados, dependencias incorrectas o respuestas que no cumplen el contrato esperado.  

Aunque son m√°s lentos y costosos que los unitarios, aportan confianza en que las piezas, adem√°s de funcionar aisladas, tambi√©n lo hacen cuando se combinan.  

Por ejemplo, con [Supertest](https://www.npmjs.com/package/supertest) podemos validar que un endpoint responda como esperamos:  

```js
import request from 'supertest';
import app from '../app';

test('GET /usuarios devuelve 200', async () => {
  const res = await request(app).get('/usuarios');
  expect(res.status).toBe(200);
});
```

<a id="funcionales"></a>
### Funcionales (o E2E)

Los **tests funcionales** o **E2E** (*end to end*) validan el sistema completo **tal como lo usar√≠a una persona real**.  

Simulan un flujo de principio a fin: abrir la aplicaci√≥n, ingresar datos, interactuar con la interfaz y comprobar el resultado final.  

Su prop√≥sito es garantizar que todas las partes del sistema ‚Äîfrontend, backend, base de datos, servicios externos‚Äî trabajen coordinadas para ofrecer la experiencia esperada.  

Son m√°s lentos y costosos de mantener que unitarios e integraci√≥n, pero son los que m√°s se acercan a la realidad del usuario. Por eso, aunque deben ser pocos, aportan un nivel de confianza que los dem√°s no pueden dar.  

Ejemplo con [Cypress](https://www.cypress.io/):  

```js
it('login exitoso (camino feliz)', () => {
  cy.visit('/login');
  cy.get('#usuario').type('ana');
  cy.get('#password').type('secreto');
  cy.contains('Ingresar').click();
  cy.url().should('include', '/home');
});
```

<a id="piramide-testing"></a>
### Pir√°mide de testing

Cuando hablamos de distintos tipos de pruebas, nos preguntamos: **¬øcu√°ntas hacer de cada una?**.

La pir√°mide de testing es una met√°fora visual que responde justamente a eso, mostrando la proporci√≥n recomendada entre unitarios, integraci√≥n y E2E.  

<p align="center">
  <img src="imagenes/piramide-testing.png" alt="Pir√°mide de testing" width="300"/>
</p>

La **base m√°s ancha** corresponde a los tests unitarios: r√°pidos y abundantes, son los que sostienen la suite.  

En el **nivel intermedio** est√°n los de integraci√≥n: menos numerosos, pero esenciales para verificar c√≥mo se combinan los m√≥dulos.  

Por √∫ltimo, en la **punta** se ubican los E2E: pocos, lentos y costosos, pero valiosos para validar los flujos cr√≠ticos de principio a fin.  

En conclusi√≥n, la pir√°mide muestra que una buena suite no se apoya en un solo tipo de test, sino en combinar varios niveles con equilibrio.

<a id="bdd"></a>
## BDD

El **Behavior-Driven Development (BDD)** es una forma de pensar el desarrollo centrada en el comportamiento esperado del sistema.  

La idea principal es que los tests no sean solo para desarrolladores, sino tambi√©n un lenguaje compartido con el negocio: escenarios que cuentan qu√© deber√≠a pasar en situaciones reales.  

Para expresar esos escenarios, se utiliza este esquema:

```gherkin
Scenario: Login exitoso
  Given un usuario v√°lido
  When ingresa su contrase√±a correcta
  Then accede al sistema
```

> **Dato**: Esta forma de escritura se llama **Gherkin**, y se apoya en el esquema **Given / When / Then**.

A diferencia de los tests cl√°sicos, que son m√°s t√©cnicos y at√≥micos, BDD utiliza escenarios completos que se leen casi como especificaciones. De esta forma, los tests cumplen dos funciones: validar el sistema y, al mismo tiempo, documentar de manera clara qu√© comportamiento se espera.

<a id="mocking"></a>
## Mocking

Muchas veces no podemos testear con los componentes reales: quiz√°s porque todav√≠a no existen, porque dependen de un servicio externo, o simplemente porque son lentos y costosos de usar en pruebas.  

En esos casos aparece el **mocking**, que consiste en crear objetos ‚Äúdobles‚Äù que imitan la interfaz de los reales pero devuelven respuestas controladas. La idea no es reemplazar su l√≥gica, sino simularla para poder avanzar.  

Imaginemos un servicio de clima que a√∫n no est√° implementado. Queremos probar una funci√≥n `vestir()` que decide la ropa seg√∫n la temperatura. En vez de esperar al servicio real, armamos un mock que devuelva el valor que nos interesa: 

```js
const climaMock = { obtener: () => ({ temp: 25 }) };

test('elige remera si hace calor', () => {
  const resultado = vestir(climaMock);
  expect(resultado).toBe('remera');
});
```

Con este objeto *bobo* (`climaMock`) ya podemos validar la l√≥gica de `vestir()` sin depender de nada externo. Adem√°s, tenemos control total sobre qu√© devuelve el mock: podemos simular tanto un resultado v√°lido como un error, haciendo que los tests sean r√°pidos, predecibles y f√°ciles de repetir.

Finalmente, mencionemos que el mocking puede hacerse a mano, como en el ejemplo, o usando librer√≠as como **Jest**. Seg√∫n el lenguaje, esto puede ser trivial (como en JavaScript, donde los objetos son din√°micos) o m√°s complejo (como en Java, donde usamos Mockito).

<a id="tdd"></a>
## üî¥üü¢ TDD

El **Test-Driven Development (TDD)** propone escribir primero el test y despu√©s el c√≥digo. Se lo suele resumir con la idea de un **sem√°foro**:

1. **Rojo**: el test falla porque la funcionalidad a√∫n no existe.  
2. **Verde**: escribimos lo m√≠nimo necesario para que el test pase.  
3. **Refactor**: mejoramos el dise√±o manteniendo los tests en *verde*.  

Este ciclo simple y repetitivo asegura que cada nueva funcionalidad nazca acompa√±ada de una prueba, y que siempre tengamos feedback inmediato sobre si el sistema sigue funcionando.


